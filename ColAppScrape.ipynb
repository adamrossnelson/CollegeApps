{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscrape college applications\n",
    "## Step One: Prepare Directory Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load directory data.\n",
    "pd.set_option('display.max_rows', 200)\n",
    "IPEDSfile = pd.read_stata('../../statadata/IPEDSDirInfo02to16smlr.dta', preserve_dtypes=False)\n",
    "\n",
    "# Reduce to 2 and 4yr institutions.\n",
    "IPEDSfile['filter'] = np.where((IPEDSfile['sector']=='Public, 4-year or above') | \n",
    "                               (IPEDSfile['sector']=='Public, 2-year') |\n",
    "                               (IPEDSfile['sector']=='Private not-for-profit, 4-year or above') |\n",
    "                               (IPEDSfile['sector']=='Private not-for-profit, 2-year'), 1, 0)\n",
    "IPEDSfile = IPEDSfile[IPEDSfile['filter']==1]\n",
    "\n",
    "# Remove www. prefix from webaddress.\n",
    "IPEDSfile['rootdom'] = IPEDSfile.loc[:, 'webaddr'].replace(regex=True, to_replace='www.', value='')\n",
    "# Remove miscellaneous slashes & other from webaddress.\n",
    "IPEDSfile['rootdom'] = IPEDSfile.loc[:, 'rootdom'].replace(regex=True, to_replace=r'/', value='')\n",
    "IPEDSfile['rootdom'] = IPEDSfile.loc[:, 'rootdom'].replace(regex=True, to_replace=r'HTTPS:', value='')\n",
    "IPEDSfile['rootdom'] = IPEDSfile.loc[:, 'rootdom'].replace(regex=True, to_replace=r'https:', value='')\n",
    "IPEDSfile['rootdom'] = IPEDSfile.loc[:, 'rootdom'].replace(regex=True, to_replace=r'about', value='')\n",
    "# IPEDSfile['rootdom'] = IPEDSfile.loc[:, 'rootdom'].replace(to_replace=NaN, value=)\n",
    "# IPEDSfile = IPEDSfile.reindex(range(len(IPEDSfile)))\n",
    "IPEDSfile = IPEDSfile.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user input regarding previous scrape attempts.\n",
    "print('Enter the school starting school root domain name. No entry will start at beginning of the list.')\n",
    "start_school = input()\n",
    "# If user provided starting school, remove schools before the starting school.\n",
    "if start_school != '':\n",
    "    new_school_loc = IPEDSfile[IPEDSfile['rootdom'] == start_school].index.tolist()[0]\n",
    "    IPEDSfile = IPEDSfile[new_school_loc:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of domains to scrape & check results.\n",
    "weblist = IPEDSfile['rootdom']\n",
    "weblist.head(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Two: Prepare Browser Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# browser = webdriver.Chrome()\n",
    "browser = webdriver.Firefox()\n",
    "print('Loaded Browser Here')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Three: Scrape For Each School"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list = []\n",
    "for school in weblist:\n",
    "    print('STARTING SCHOOL', str(school).upper())\n",
    "    searchstr = ''.join((r'https://www.google.com/search?q=',\n",
    "                         r'application+admission+AND+(printable+OR+paper+OR+mail)+site:', \n",
    "                         school, r'+filetype:pdf'))\n",
    "    print('Search string is ', searchstr)\n",
    "    browser.get(searchstr)\n",
    "    results = browser.find_elements_by_css_selector('h3 > a')\n",
    "\n",
    "    if len(results) == 0:\n",
    "        try:\n",
    "            check_captcha = browser.find_element_by_partial_link_text('Why did this happen')\n",
    "            print('At school, ', school.lower(), 'Google responded with CAPTCHA - Will wait for user input.', end='\\n\\n')\n",
    "            error_list.append(''.join((school, '-', '.', '-EncounteredCAPTCHA-', '.')))\n",
    "            discarded_wait = input()\n",
    "            results = browser.find_elements_by_css_selector('h3 > a')\n",
    "        except:\n",
    "            print('No results for school ', school.lower(), end='\\n\\n')\n",
    "            error_list.append(''.join((school, '-', '.', '-NoResults-', '.')))\n",
    "            sleep(.5)\n",
    "\n",
    "    if len(results) < 3:\n",
    "        doc_count = len(results)\n",
    "        print('There were {} results from Google. Will download all.'.format(len(results)))\n",
    "        sleep(.1)\n",
    "    else:\n",
    "        doc_count = 3\n",
    "        print('There were 10 or more results from Google. Will download first three.')\n",
    "        sleep(.2)\n",
    "\n",
    "    for i in range(doc_count):\n",
    "        filelink = results[i].get_attribute('href')\n",
    "        try:\n",
    "            pdf = requests.get(filelink)\n",
    "            fname = ''.join((school, str(i), '.pdf'))\n",
    "            open(''.join((r'pprapps/', fname)), 'wb').write(pdf.content)\n",
    "            print('Filelink = ' + filelink)\n",
    "            print('Saved as : ' + fname)\n",
    "            print('Header info :' + str(pdf.headers), end='\\n\\n')\n",
    "        except ConnectionError:\n",
    "            print('There was a ConnectionError on the {}th iteration at : {}'.format(str(i), school.lower()))\n",
    "            error_list.append(''.join((school, '-', str(i), '-ConnectionError-', filelink)))\n",
    "            sleep(.1)\n",
    "        except:\n",
    "            print('There was an UnspecifiedError on the {}th iteration at : {}'.format(str(i), school))\n",
    "            error_list.append(''.join((school, '-', str(i), '-UnspecifiedError-', filelink)))\n",
    "            sleep(.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for errors in range(len(error_list)):\n",
    "    print(error_list[errors])\n",
    "    \n",
    "# Encountered CAPTCHA at stillman.edu               April 17, 2018\n",
    "# Encountered NaN after alaskapacific.edu           April 18, 2018\n",
    "# Encountered CAPTCHA at buc.edu                    April 18, 2018\n",
    "# Program STALLED at arapahoe.edu                   April 18, 2018"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
